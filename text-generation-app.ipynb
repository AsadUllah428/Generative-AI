{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5181c78",
   "metadata": {},
   "source": [
    "You're looking for a comprehensive breakdown of the provided Python code, first with a detailed explanation of its components and functionality, followed by the code itself annotated with inline comments. This will be perfect for your GenAI GitHub repository under a file named text_generation.\n",
    "\n",
    "Text Generation with Azure AI Inference\n",
    "This repository demonstrates how to leverage the Azure AI Inference SDK in Python to interact with large language models (LLMs) hosted on Azure. We'll explore two distinct scenarios: a basic question-and-answer interaction and a more dynamic, user-driven recipe generation tool.\n",
    "\n",
    "Detailed Explanation\n",
    "This Python script showcases how to connect to an Azure AI service and utilize its chat completion capabilities for text generation. It's divided into two main examples, each illustrating different aspects of interacting with an LLM.\n",
    "\n",
    "## 1. Environment Setup and Authentication:\n",
    "\n",
    "pip install azure-ai-inference python-dotenv: The first line (commented out as it's a shell command) indicates the necessary libraries. azure-ai-inference is the official SDK for interacting with Azure AI services, and python-dotenv is used for loading environment variables from a .env file.\n",
    "\n",
    "load_dotenv(): This function from the dotenv library loads key-value pairs from a .env file into your script's environment. This is a crucial security practice as it prevents hardcoding sensitive information like API keys directly into your code.\n",
    "\n",
    "os.getenv(\"VARIABLE_NAME\"): This method safely retrieves the value of an environment variable. It returns None if the variable is not found, which is safer than os.environ[\"VARIABLE_NAME\"] which would raise a KeyError.\n",
    "\n",
    "AZURE_AI_INFERENCE_ENDPOINT, AZURE_AI_INFERENCE_API_KEY, AZURE_AI_INFERENCE_MODEL_NAME: These are the expected environment variables that must be present in your .env file. They define where your Azure AI service is located, the key to authenticate your requests, and the specific model deployment you wish to use.\n",
    "\n",
    "ChatCompletionsClient: This is the core class from the azure.ai.inference SDK. You instantiate it by providing your service endpoint, an AzureKeyCredential (which wraps your API key for authentication), and the api_version. The API version ensures compatibility with the specific features and structure of the Azure AI service you are targeting.\n",
    "\n",
    "## 2. Core Chat Completion Concepts:\n",
    "\n",
    "messages List: The interaction with the AI model is structured as a list of \"messages.\" This format is common in conversational AI and allows you to build a dialogue history.\n",
    "\n",
    "SystemMessage: This type of message is used to set the context, persona, or instructions for the AI model. It's like telling the AI, \"You are a helpful assistant.\" or \"You are a recipe generator.\" This helps guide the AI's responses and ensures it behaves as intended.\n",
    "\n",
    "UserMessage: This message type represents the actual input or query from the user (or your application). It's what you're asking the AI to respond to.\n",
    "\n",
    "client.complete(): This method sends the messages list to the Azure AI model.\n",
    "\n",
    "max_tokens: This parameter controls the maximum length of the AI's generated response. It's measured in \"tokens,\" which can be thought of as parts of words. Setting this helps manage response size and cost.\n",
    "\n",
    "model: This parameter specifies which particular large language model deployment within your Azure AI service should be used for the completion.\n",
    "\n",
    "Response Structure (response.choices[0].message.content): The complete() method returns a response object. This object typically contains a list of choices (if the model generates multiple possible completions). We usually access the first choice (choices[0]) and then retrieve the actual text content from its message.content attribute.\n",
    "\n",
    "## 3. Code Example 1: Simple Question and Answer\n",
    "\n",
    "This is a straightforward demonstration. It initializes the client and then sends a fixed SystemMessage (\"You are a helpful assistant.\") and a fixed UserMessage (\"I am going to Paris, what should I see?\").\n",
    "\n",
    "The max_tokens is set to a relatively high value (2048) to allow for a detailed response.\n",
    "\n",
    "The model's generated content, which would be travel recommendations for Paris, is then printed to the console.\n",
    "\n",
    "## 4. Code Example 2: Dynamic Recipe Generation\n",
    "\n",
    "This example elevates the interaction by incorporating user input, making the prompt dynamic.\n",
    "\n",
    "input(): This built-in Python function is used to prompt the user for input from the console. The script asks for the number of recipes and a list of ingredients.\n",
    "\n",
    "F-string for Dynamic Prompt (prompt = f\"...\"): An f-string is used to embed the user's no_recipes and ingredients directly into the UserMessage content. This creates a highly customized prompt based on real-time user input.\n",
    "\n",
    "Specific SystemMessage: For this task, the SystemMessage is tailored: \"You are a helpful assistant that provides clear recipe suggestions.\" This refines the AI's behavior to specifically focus on recipe generation.\n",
    "\n",
    "max_tokens=600: The max_tokens is set to a more moderate value here, anticipating that recipes might not require extremely long responses and to manage output verbosity.\n",
    "\n",
    "The generated recipes, adhering to the user's specified number and ingredients, are then printed.\n",
    "\n",
    "In summary, these examples illustrate the fundamental steps of setting up an Azure AI client, preparing different types of messages, sending requests to an LLM, and processing its responses for various text generation tasks, from simple queries to dynamic content creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a244d39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'source' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-inference in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (1.0.0b9)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from azure-ai-inference) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from azure-ai-inference) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from azure-ai-inference) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-inference) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-inference) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asadmunir\\anaconda3\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Install openai package\n",
    "!pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c7cb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Paris Travel Suggestions ---\n",
      "<think>\n",
      "Okay, the user is asking about what to see in Paris. That's a classic travel question, but I should approach it thoughtfully. They didn't specify their interests or travel style, so I'll need to cover a broad range while keeping it digestible. \n",
      "\n",
      "Hmm, Paris has so much to offer - first-timers usually want the iconic sights, but I should also sprinkle in some local gems. The Eiffel Tower is non-negotiable of course, but I'll mention both the classic views and the less crowded Trocad√©ro angle. For museums, I should note the Louvre's overwhelming size and suggest focusing - maybe add that tip about the underground entrance to save time. \n",
      "\n",
      "Ah, the Seine river cruises! Touristy but magical at night - that's worth emphasizing. And Montmartre... I feel like warning about crowds but also describing that village charm. Should I mention the Clignancourt flea market? Maybe not for first-timers - too overwhelming. \n",
      "\n",
      "Wait, they didn't say how long they're staying. Better structure it by priority: absolute must-sees first, then tier two. And practical tips at the end - Paris logistics can trip people up. The museum pass is golden, and I must warn about pickpockets near monuments. \n",
      "\n",
      "Oh! Food. Can't just list sights without mentioning patisseries or caf√© culture. But I'll keep it brief - \"fuel up\" gets the idea across. Maybe add that thing about asking for tap water to save money? No, that might be too nitty-gritty. \n",
      "\n",
      "...Did I cover neighborhoods properly? Le Marais for history, Saint-Germain for literature... Latin Quarter's student vibe... yes. And ended with the \"choose your own adventure\" bit - important since everyone enjoys Paris differently. \n",
      "\n",
      "Final check: balanced icons with local flavor, practical advice, poetic but not fluffy. Should work whether they're a honeymooner or solo backpacker.\n",
      "</think>\n",
      "Paris is a dazzling city with endless sights! Here's a curated list of **must-see attractions**, balancing iconic landmarks with authentic local experiences:\n",
      "\n",
      "### üèõÔ∏è **Iconic Landmarks (The Classics)**\n",
      "1.  **Eiffel Tower:** Go *at least* twice: once by day for the structure, and once at night for the sparkling lights (every hour on the hour). Consider booking tickets *well in advance* for the summit, or enjoy the view from Trocad√©ro Gardens or Champ de Mars.\n",
      "2.  **Louvre Museum:** Even if you're not an art lover, the scale and history are astounding. Prioritize: *Mona Lisa*, *Venus de Milo*, *Winged Victory*. **Tip:** Use the Carrousel du Louvre entrance to avoid long lines.\n",
      "3.  **Notre-Dame Cathedral:** Still majestic despite the 2019 fire. Admire the facade and explore √éle de la Cit√©. The restoration is ongoing, but the exterior and square are powerful.\n",
      "4.  **Arc de Triomphe & Champs-√âlys√©es:** Climb the Arc for stunning 360¬∞ views down 12 radiating avenues. Walk the Champs-√âlys√©es (window shopping is free!).\n",
      "5.  **Sainte-Chapelle:** On √éle de la Cit√©. Breathtaking stained glass windows in a hidden gem of Gothic architecture. Book tickets ahead.\n",
      "\n",
      "### üé® **Art & Culture (Beyond the Louvre)**\n",
      "6.  **Mus√©e d'Orsay:** Housed in a stunning former railway station. Masterpieces of Impressionism & Post-Impressionism (Van Gogh, Monet, Renoir, Degas).\n",
      "7.  **Centre Pompidou:** Modern & contemporary art in a radical inside-out building. Great views from the top.\n",
      "8.  **Montmartre & Sacr√©-C≈ìur:** Wander charming, hilly streets, see artists at Place du Tertre, visit the Moulin Rouge, and enjoy panoramic city views from the white-domed Sacr√©-C≈ìur Basilica.\n",
      "\n",
      "### üå≥ **Neighborhoods & Atmosphere**\n",
      "9.  **Le Marais:** Historic, trendy district with medieval streets, chic boutiques, Jewish quarter (rue des Rosiers), museums (Carnavalet - History of Paris, Picasso Museum), and vibrant LGBTQ+ scene.\n",
      "10. **Saint-Germain-des-Pr√©s:** Literary & intellectual heart (Caf√© de Flore, Les Deux Magots), elegant boutiques, art galleries, and the beautiful Jardin du Luxembourg nearby.\n",
      "11. **Latin Quarter:** Student hub around the Sorbonne. Lively atmosphere, bookshops (Shakespeare & Company), the Panth√©on, and the charming Jardin des Plantes.\n",
      "12. **Seine River Cruise:** A classic way to see major monuments from the water, especially magical at sunset or night. Bateaux Mouches is famous, but smaller companies offer charm.\n",
      "\n",
      "### ‚ú® **Hidden Gems & Local Favorites**\n",
      "13. **P√®re Lachaise Cemetery:** Peaceful, atmospheric walk among the tombs of famous figures (Jim Morrison, Oscar Wilde, Edith Piaf, Chopin).\n",
      "14. **Mus√©e Rodin:** Beautiful sculpture garden featuring \"The Thinker\" and \"The Gates of Hell.\" A tranquil oasis.\n",
      "15. **Palais Royal Gardens:** Elegant gardens surrounded by arcades with unique striped columns (Colonnes de Buren). Chic and less touristy.\n",
      "16. **Canal Saint-Martin:** Trendy local spot for picnics, canal-side cafes, and watching the locks operate. Great for a relaxed afternoon.\n",
      "\n",
      "### üçΩÔ∏è **Essential Tips**\n",
      "*   **Walk & Metro:** Paris is best explored on foot in neighborhoods, but the Metro is efficient for longer distances. Get a carnet (pack of 10 tickets) or a Navigo pass if staying longer.\n",
      "*   **Museum Pass:** Consider the Paris Museum Pass if you plan to visit several museums/monuments. It saves money and time (skip-the-line access).\n",
      "*   **Caf√© Culture:** Sit at a sidewalk caf√©, order a coffee or wine, and simply watch the world go by. It's quintessential Paris.\n",
      "*   **Pastries & Food:** Indulge in croissants, baguettes, macarons (Ladur√©e, Pierre Herm√©), and explore local markets (March√© Bastille, March√© d'Aligre).\n",
      "*   **Be Aware:** Watch out for pickpockets, especially in crowded areas and on the Metro. Be polite (\"Bonjour\" goes a long way!).\n",
      "\n",
      "**Choose what resonates most with you!** Paris offers history, art, food, fashion, and romance. Even getting \"lost\" wandering its beautiful streets is a delight. Bon voyage! üá´ÔøΩ\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary package if you haven't already\n",
    "# It's good practice to include this for anyone trying to run the code.\n",
    "# !pip install azure-ai-inference python-dotenv\n",
    "\n",
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file.\n",
    "# This is a critical step for secure credential management, preventing API keys\n",
    "# from being hardcoded directly into the script.\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve values from environment variables.\n",
    "# os.getenv() is preferred over os.environ[] as it returns None if the\n",
    "# variable is not found, avoiding a KeyError.\n",
    "endpoint = os.getenv(\"AZURE_AI_INFERENCE_ENDPOINT\")\n",
    "api_key = os.getenv(\"AZURE_AI_INFERENCE_API_KEY\")\n",
    "model_name = os.getenv(\"AZURE_AI_INFERENCE_MODEL_NAME\")\n",
    "\n",
    "# Check if environment variables are loaded correctly (optional but good practice)\n",
    "if not all([endpoint, api_key, model_name]):\n",
    "    print(\"Error: Please ensure AZURE_AI_INFERENCE_ENDPOINT, AZURE_AI_INFERENCE_API_KEY, and AZURE_AI_INFERENCE_MODEL_NAME are set in your .env file.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize the ChatCompletionsClient.\n",
    "# This client is the primary interface for sending chat completion requests to Azure AI.\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,                           # The URL of your Azure AI service endpoint.\n",
    "    credential=AzureKeyCredential(api_key),      # Your API key wrapped in an AzureKeyCredential for authentication.\n",
    "    api_version=\"2024-05-01-preview\"             # Specifies the API version to ensure compatibility with features.\n",
    ")\n",
    "\n",
    "# Make a completion call to the Azure AI model.\n",
    "# The 'messages' parameter expects a list of message objects, defining the conversation context.\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        # SystemMessage sets the overall behavior or persona of the assistant.\n",
    "        # This tells the AI how to act (e.g., \"You are a helpful assistant.\").\n",
    "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "        # UserMessage contains the actual prompt or question from the user.\n",
    "        # This is what you're asking the AI to respond to.\n",
    "        UserMessage(content=\"I am going to Paris, what should I see?\"),\n",
    "    ],\n",
    "    max_tokens=2048, # Limits the maximum number of tokens (words/characters) in the model's response.\n",
    "                     # A higher value allows for more detailed answers.\n",
    "    model=model_name # Specifies which deployed model (e.g., \"gpt-4\", \"gpt-35-turbo\") to use.\n",
    ")\n",
    "\n",
    "# Print the content of the model's response.\n",
    "# The response object typically contains a list of 'choices' (e.g., if multiple completions were requested).\n",
    "# We access the first choice ([0]) and then its message content.\n",
    "print(\"--- Paris Travel Suggestions ---\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58480572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating recipes... Please wait ---\n",
      "\n",
      "<think>\n",
      "We are given one ingredient: banana.\n",
      " We need to provide one recipe that uses banana.\n",
      " Since the user only provided \"banana\", we can assume that the recipe should primarily feature banana.\n",
      " A simple and popular recipe that uses banana is Banana Bread.\n",
      "\n",
      " Recipe: Classic Banana Bread\n",
      "\n",
      " Ingredients:\n",
      " - 2 to 3 ripe bananas (about 1 cup mashed)\n",
      " - 1/3 cup (76g) melted butter, unsalted or salted\n",
      " - 1/2 teaspoon baking soda\n",
      " - 1 pinch salt\n",
      " - 3/4 cup (150g) sugar (can reduce to 2/3 cup if desired)\n",
      " - 1 large egg, beaten\n",
      " - 1 teaspoon vanilla extract\n",
      " - 1 1/2 cups (190g) all-purpose flour\n",
      "\n",
      " Note: The user only provided banana, so we are listing the entire set of ingredients for the recipe, but note that the user might not have all of these. However, as per the instruction, we are to list the recipe with the given ingredient (banana) and the other necessary ingredients.\n",
      "\n",
      " We are only required to show one recipe.\n",
      "\n",
      " Let's write the recipe for Banana Bread.\n",
      "</think>\n",
      "### Recipe: Simple Banana Bread  \n",
      "**Ingredients:**  \n",
      "- 3 ripe bananas (mashed)  \n",
      "- 1/3 cup melted butter (unsalted)  \n",
      "- 1 teaspoon baking soda  \n",
      "- Pinch of salt  \n",
      "- 3/4 cup granulated sugar  \n",
      "- 1 large egg (beaten)  \n",
      "- 1 teaspoon vanilla extract  \n",
      "- 1 ¬Ω cups all-purpose flour  \n",
      "\n",
      "**Instructions:**  \n",
      "1. Preheat oven to 350¬∞F (175¬∞C). Grease a 4x8-inch loaf pan.  \n",
      "2. Mash bananas in a bowl. Stir in melted butter.  \n",
      "3. Mix in baking soda, salt, sugar, beaten egg, and vanilla.  \n",
      "4. Gently fold in flour until just combined (do not overmix).  \n",
      "5. Pour batter into the pan. Bake 50‚Äì60 minutes, or until a toothpick inserted comes out clean.  \n",
      "6. Cool in the pan for 10 minutes, then transfer to a wire rack. Slice and serve!  \n",
      "\n",
      "> Note: Optional add-ins like nuts or chocolate chips can be included. Enjoy warm or at room temperature! üçåüçû\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the ChatCompletionsClient.\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(api_key),\n",
    "    api_version=\"2024-05-01-preview\" # Your desired API version.\n",
    ")\n",
    "\n",
    "# --- NEW PROMPT LOGIC: Dynamically generate prompts based on user input ---\n",
    "# Prompt the user to input the desired number of recipes.\n",
    "no_recipes = input(\"Enter the number of recipes you want (e.g., 5): \")\n",
    "# Prompt the user to input a comma-separated list of ingredients.\n",
    "ingredients = input(\"Enter a list of ingredients (e.g., chicken, potatoes, and carrots): \")\n",
    "\n",
    "# Construct the prompt string using an f-string.\n",
    "# This allows embedding the user's inputs directly into the request sent to the AI model,\n",
    "# making the interaction dynamic and personalized.\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used.\"\n",
    "\n",
    "# Create the messages list for the API call.\n",
    "# This structure defines the conversation context for the AI.\n",
    "messages = [\n",
    "    # SystemMessage sets the AI's role specifically for recipe suggestions.\n",
    "    SystemMessage(content=\"You are a helpful assistant that provides clear recipe suggestions.\"),\n",
    "    # UserMessage contains the dynamically generated request from the user.\n",
    "    UserMessage(content=prompt)\n",
    "]\n",
    "# --- END NEW PROMPT LOGIC ---\n",
    "\n",
    "# Inform the user that recipe generation is in progress for a better user experience.\n",
    "print(\"\\n--- Generating recipes... Please wait ---\\n\")\n",
    "\n",
    "# Make the completion call with the new dynamic prompt and specified max_tokens.\n",
    "completion = client.complete(\n",
    "    messages=messages,\n",
    "    max_tokens=600,  # Limits the response length. A moderate value is chosen as recipes\n",
    "                     # can be long but we might not need an entire cookbook.\n",
    "    model=model_name # Specifies the deployed model to be used.\n",
    ")\n",
    "\n",
    "# Print the generated recipes from the model's response.\n",
    "print(completion.choices[0].message.content)\n",
    "print(\"\\n--------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
