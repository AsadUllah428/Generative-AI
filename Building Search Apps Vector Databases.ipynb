{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f8c30c5",
   "metadata": {},
   "source": [
    "# Detailed Explanation of the Python Semantic Search Script\n",
    "This script is a command-line tool designed to perform a semantic search on a dataset of videos. Instead of searching for exact keywords, it uses a pre-trained machine learning model to find videos that are conceptually or semantically similar to a user's query.\n",
    "\n",
    "## Here's a breakdown of how it works, function by function:\n",
    "\n",
    "### Overall Purpose\n",
    "The program's main loop prompts the user for a text query. It then uses the Azure OpenAI API to convert that query into a numerical representation called a vector embedding. It compares this query vector to pre-computed vector embeddings for a collection of videos, finds the most similar ones, and displays their details.\n",
    "\n",
    "load_dataset(source: str) -> pd.core.frame.DataFrame\n",
    "\n",
    "This function is responsible for ingesting your data.\n",
    "\n",
    "- It reads a JSON file (in this case, embedding_index_3m.json) which is assumed to contain a list of video records. Each record likely has metadata (like title, videoId, summary, speaker) and a pre-calculated embedding vector (e.g., under a key like ada_v2).\n",
    "\n",
    "- pd.read_json(source) reads the file into a pandas DataFrame, a powerful data structure for tabular data.\n",
    "\n",
    "- .drop(columns=[\"text\"], errors=\"ignore\") removes a column named \"text\" if it exists. This is likely the original source text used to generate the embeddings, and it's no longer needed for the search.\n",
    "\n",
    "- .fillna(\"\") ensures that any missing values in the DataFrame are replaced with an empty string, preventing potential errors later in the code.\n",
    "\n",
    "cosine_similarity(a, b)\n",
    "This is the core mathematical function for measuring similarity between two vectors.\n",
    "\n",
    "- What is Cosine Similarity? It's a metric that measures the cosine of the angle between two vectors in a multidimensional space. A score of 1 means the vectors point in the exact same direction (perfect similarity), a score of 0 means they are orthogonal (no similarity), and a score of -1 means they are opposite. In the context of embeddings, this score is a reliable way to determine how semantically related two pieces of text are.\n",
    "\n",
    "- The function first checks if the input vectors a and b have different lengths. If so, it pads the shorter vector with zeros to ensure they can be multiplied element-wise.\n",
    "\n",
    "- It then calculates the dot product of the two vectors and divides it by the product of their magnitudes (norms), which gives you the cosine of the angle between them.\n",
    "\n",
    "get_videos(query: str, dataset: pd.core.frame.DataFrame, rows: int) -> pd.core.frame.DataFrame\n",
    "\n",
    "This is the main search function.\n",
    "\n",
    "- It takes a user's query, your dataset DataFrame, and the number of rows to return.\n",
    "\n",
    "- client.embeddings.create(input=query, model=model) is the crucial API call. It sends the user's query to the Azure OpenAI service and receives a vector embedding in return.\n",
    "\n",
    "- video_vectors[\"similarity\"] = ... calculates the similarity score for every video in the dataset. It applies the cosine_similarity function to the query_embeddings and each video's pre-calculated ada_v2 embedding.\n",
    "\n",
    "- mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD filters the dataset, keeping only the videos with a similarity score above a certain threshold. This helps to eliminate irrelevant results.\n",
    "\n",
    "- .sort_values(by=\"similarity\", ascending=False) sorts the filtered videos from most similar to least similar.\n",
    "\n",
    "- .head(rows) returns the top N results, where N is the value of the rows parameter.\n",
    "\n",
    "display_results(videos: pd.core.frame.DataFrame, query: str)\n",
    "\n",
    "This function handles the output presentation.\n",
    "\n",
    "- It takes the DataFrame of top videos and the original query.\n",
    "\n",
    "- It iterates through each video in the DataFrame.\n",
    "\n",
    "- For each video, it prints out key information in a clean, readable format, including the title, a summary snippet, the YouTube URL (with a timestamp), the calculated similarity score, and the speakers.\n",
    "\n",
    "Main Execution Block\n",
    "\n",
    "The code at the bottom of the script handles the program's lifecycle.\n",
    "\n",
    "- It first loads the dataset using load_dataset(DATASET_NAME).\n",
    "\n",
    "- It then enters an infinite while True: loop to continuously prompt the user for a new query.\n",
    "\n",
    "- The loop breaks if the user types \"exit\".\n",
    "\n",
    "- For each query, it calls get_videos to perform the search and display_results to print the output.\n",
    "\n",
    "Security for a Public GitHub Repository\n",
    "\n",
    "You are using a very secure method for handling your API key.\n",
    "\n",
    "- from dotenv import load_dotenv and load_dotenv() correctly load your key from a local .env file.\n",
    "\n",
    "- os.environ['AZURE_OPENAI_API_KEY'] retrieves this key from the environment variables, meaning it is never hardcoded in the script itself.\n",
    "\n",
    "This is a critical best practice. As long as you do not upload the .env file to your GitHub repository, your API key remains private and secure, and the script can be shared publicly without risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b908a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Videos similar to 'rstudio and notebook':\n",
      " - Reproducible Data Science with Machine Learning\n",
      "   Summary: A separate team is responsible for deploying machine learning models, which aligns well with the...\n",
      "   YouTube: https://youtu.be/NyWOfYKScUk?t=553\n",
      "   Similarity: 0.8509\n",
      "   Speakers: Rafal Lukawiecki\n",
      " - Reproducible Data Science with Machine Learning\n",
      "   Summary: In this video, Rafal Lukawiecki discusses reproducible data science with machine learning. He demonstrates how...\n",
      "   YouTube: https://youtu.be/NyWOfYKScUk?t=1289\n",
      "   Similarity: 0.8477\n",
      "   Speakers: Rafal Lukawiecki\n",
      " - Edit and run Jupyter notebooks without leaving Azure Machine Learning studio\n",
      "   Summary: The video demonstrates the features of Studio Notebooks in Azure Machine Learning. Users can easily...\n",
      "   YouTube: https://youtu.be/AAj-Fz0uCNk?t=184\n",
      "   Similarity: 0.8435\n",
      "   Speakers: Abe Omorogbe\n",
      " - Using R with Azure Machine Learning\n",
      "   Summary: The video demonstrates how to use Visual Studio Code (VS Code) for an interactive R...\n",
      "   YouTube: https://youtu.be/ZjsTg2v5aSQ?t=183\n",
      "   Similarity: 0.8430\n",
      "   Speakers: Seth, Marck\n",
      " - Edit and run Jupyter notebooks without leaving Azure Machine Learning studio\n",
      "   Summary: Azure Machine Learning Studio Notebooks offer a streamlined workflow for data scientists. The gather feature...\n",
      "   YouTube: https://youtu.be/AAj-Fz0uCNk?t=740\n",
      "   Similarity: 0.8357\n",
      "   Speakers: Abe Omorogbe\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file.\n",
    "# This is a critical security practice for not exposing API keys\n",
    "# and other sensitive information in a public repository.\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "# Get API key, model deployment name, and endpoint from environment variables.\n",
    "# This makes the code secure and flexible.\n",
    "try:\n",
    "    api_key = os.environ['AZURE_OPENAI_API_KEY']\n",
    "    # The deployment name is the name of the model you deployed in the Azure Portal.\n",
    "    model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "    # If using an older API version, you might also need the endpoint explicitly:\n",
    "    # endpoint = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing environment variable {e}. Please check your .env file.\")\n",
    "    # Exit the program if a required environment variable is not set.\n",
    "    exit()\n",
    "\n",
    "# Initialize the AzureOpenAI client with the API key.\n",
    "# The client is the main interface for communicating with the Azure OpenAI service.\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    api_version=\"2023-05-15\"\n",
    ")\n",
    "\n",
    "# --- Constants ---\n",
    "# Similarity threshold for filtering results. Only videos with a score above this\n",
    "# will be considered. The value 0.75 is a good starting point.\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "\n",
    "# The name of the local JSON dataset file containing video metadata and embeddings.\n",
    "# It is assumed this file is in the same directory as the script.\n",
    "DATASET_NAME = \"embedding_index_3m.json\"\n",
    "\n",
    "\n",
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the video session index from a JSON file into a pandas DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        source (str): The path to the JSON dataset file.\n",
    "    \n",
    "    Returns:\n",
    "        pd.core.frame.DataFrame: The loaded and pre-processed DataFrame.\n",
    "                                 Returns an empty DataFrame if the file is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the JSON file into a DataFrame.\n",
    "        pd_vectors = pd.read_json(source)\n",
    "        # Drop the original text column, as we only need the embeddings for search.\n",
    "        # errors=\"ignore\" prevents the code from failing if the column doesn't exist.\n",
    "        return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Dataset file not found at '{source}'. Please ensure the file exists.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the cosine similarity between two numpy arrays.\n",
    "    \n",
    "    This function measures the conceptual similarity between two embeddings.\n",
    "    A score of 1 means perfect similarity, 0 means no similarity.\n",
    "    \n",
    "    Args:\n",
    "        a (np.ndarray): The first vector (e.g., the query embedding).\n",
    "        b (np.ndarray): The second vector (e.g., a video's embedding).\n",
    "        \n",
    "    Returns:\n",
    "        float: The calculated cosine similarity score.\n",
    "    \"\"\"\n",
    "    # Ensure both vectors have the same length by padding the shorter one with zeros.\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    \n",
    "    # Calculate the dot product.\n",
    "    dot_product = np.dot(a, b)\n",
    "    # Calculate the norms (magnitudes) of the vectors.\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "\n",
    "    # Avoid division by zero in case of an empty vector.\n",
    "    if norm_a == 0 or norm_b == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs a semantic search on the video dataset using an embeddings model.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query from the user.\n",
    "        dataset (pd.core.frame.DataFrame): The DataFrame containing video data and embeddings.\n",
    "        rows (int): The number of top results to return.\n",
    "        \n",
    "    Returns:\n",
    "        pd.core.frame.DataFrame: A DataFrame of the top `rows` most similar videos.\n",
    "                                 Returns an empty DataFrame on error.\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataset to avoid modifying the original DataFrame.\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    try:\n",
    "        # Get the embeddings for the user's query from the Azure OpenAI API.\n",
    "        # This is where the query is transformed into a vector.\n",
    "        query_embeddings = client.embeddings.create(\n",
    "            input=query, \n",
    "            model=model\n",
    "        ).data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while getting embeddings from Azure: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Apply the cosine similarity function to each row's embedding in the DataFrame.\n",
    "    # This calculates the similarity score between the query and every video.\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # Create a boolean mask to filter out videos with a low similarity score.\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # Sort the videos by their similarity score in descending order.\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False)\n",
    "\n",
    "    # Return the top N videos.\n",
    "    return video_vectors.head(rows)\n",
    "\n",
    "\n",
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    \"\"\"\n",
    "    Prints the search results in a user-friendly format to the console.\n",
    "    \n",
    "    Args:\n",
    "        videos (pd.core.frame.DataFrame): The DataFrame of video results.\n",
    "        query (str): The original search query.\n",
    "    \"\"\"\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"Helper function to generate a YouTube URL with a timestamp.\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    # Check if any videos were found after filtering.\n",
    "    if videos.empty:\n",
    "        print(\" - No videos found with a high enough similarity score.\")\n",
    "        return\n",
    "\n",
    "    # Loop through the top videos and print their details.\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        # Format the similarity score to 4 decimal places for readability.\n",
    "        print(f\"   Similarity: {row['similarity']:.4f}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")\n",
    "\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the dataset once at the start of the program.\n",
    "    pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "    # If the dataset failed to load, exit the program.\n",
    "    if pd_vectors.empty:\n",
    "        exit()\n",
    "\n",
    "    # Start a loop to get user queries.\n",
    "    while True:\n",
    "        # Prompt the user for input.\n",
    "        query = input(\"Enter a query (or type 'exit' to quit): \")\n",
    "        \n",
    "        # Check for the exit command.\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        \n",
    "        # Perform the search and display the top 5 results.\n",
    "        videos = get_videos(query, pd_vectors, 5)\n",
    "        display_results(videos, query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
